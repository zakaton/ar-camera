<html>
  <head>
    <title>Quest Pro | AR Camera</title>
    <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
    <script src="https://rawgit.com/blairmacintyre/aframe-look-at-billboard-component/master/dist/aframe-look-at-billboard-component.min.js"></script>
  </head>

  <style>
    html,
    body {
      margin: 0;
      padding: 0;
    }
    #overlay {
      position: absolute;
      z-index: 1;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    #overlay .clickable {
      pointer-events: all;
    }
    #overlay .hidden {
      display: none;
    }
  </style>

  <body>
    <a-scene>
      <a-assets></a-assets>

      <a-camera id="camera">
        <a-entity position="0 0 -0.4" id="hud">
          <a-entity
            position="0 0 0"
            id="transcriptText"
            geometry="primitive: plane; width: 1; height: auto"
            material="color: yellow; shader: flat; opacity: 0.7"
            text="value: This text will be 4 units wide.; color: black; wrap-count: 20; align: center; shader: flat;"
          ></a-entity>
        </a-entity>
      </a-camera>
    </a-scene>
  </body>

  <script>
    const scene = document.querySelector("a-scene");
    const assets = scene.querySelector("a-assets");

    const transcriptText = document.getElementById("transcriptText");
    function setTranscriptText(value, color) {
      setTextValue(transcriptText, value);
      setTextColor(transcriptText, color);
    }
    function setTextColor(entity, color) {
      if (color) {
        entity.setAttribute("text", "color", color);
      }
    }
    function setTextValue(entity, value) {
      if (value) {
        entity.setAttribute("text", "value", value);
        updateTextSize(entity);
      }
    }
    function updateTextSize(entity) {
      entity.setAttribute(
        "geometry",
        "height",
        (entity.components["text"].geometry.layout.height *
          entity.components["text"].geometry.layout._linesTotal) /
          1000
      );
    }

    let imageList;
    async function listImages() {
      const response = await fetch("/api/image/list");
      imageList = await response.json();
      console.log(imageList);
    }
    async function getImages() {
      if (!imageList) {
        await listImages();
      }
      imageList.forEach(async (imageName) => {
        await getImage(imageName);
      });
    }
    async function getImage(imageName) {
      const response = await fetch(`/api/image/get?name=${imageName}`);
      const blob = await response.blob();
      const image = new Image();
      console.log(blob);
      image.src = URL.createObjectURL(blob);
      console.log(image);
      // FILL - add to assets and whatnot...
      // FILL - replace existing image if already in assets
      document.body.appendChild(image);
    }
    async function renameImage(oldImageName, newImageName) {
      const response = await fetch(
        `/api/image/rename?oldName=${oldImageName}&newName=${newImageName}`
      );
      const json = await response.json();
      // FILL - rename existing images
      await listImages();
    }

    // WEBSOCKETS
    let ws;
    function initWebsocket() {
      ws = new WebSocket(`wss://${location.host}`);
      console.log(ws);
      ws.addEventListener("open", () => {
        console.log("opened websocket connection");
      });
      ws.addEventListener("close", () => {
        console.log("websocket connection closed");
        setTimeout(() => {
          initWebsocket();
        }, 1000);
      });
      ws.addEventListener("message", async (event) => {
        const blob = event.data;
        const arrayBuffer = await blob.arrayBuffer();
        const message = JSON.parse(textDecoder.decode(arrayBuffer));
        onMessage(message);
      });
    }
    function isWebsocketConnected() {
      return ws.readyState == WebSocket.OPEN;
    }
    function sendMessage(message) {
      if (isWebsocketConnected()) {
        ws.send(JSON.stringify(message));
      }
    }
    function onMessage(message) {
      console.log("received message", message);
      switch (message.type) {
        case "speechRecognition":
          {
            const { isFinal, transcript } = message;
            // FILL - put transcript in text
            // color text is "isFinal"

            if (isFinal) {
              onSpeechTranscript(transcript);
            }
          }
          break;
        default:
          console.log("uncaught message type", message.type);
          break;
      }
      console.log(message);
    }

    const canvas = document.createElement("canvas");
    const ctx = canvas.getContext("2d");

    const textDecoder = new TextDecoder();
    const textEncoder = new TextEncoder();

    initWebsocket();

    function onSpeechTranscript(transcript) {
      // FILL
    }
  </script>
</html>
